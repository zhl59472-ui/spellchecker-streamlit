{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat_minor": 5,
  "nbformat": 4,
  "cells": [
    {
      "id": "806b610b-2b8f-4a29-aad3-c2140a49fa02",
      "cell_type": "code",
      "source": "\n!pip install pyspellchecker\n",
      "metadata": {
        "trusted": true,
        "scrolled": true
      },
      "outputs": [
        {
          "ename": "<class 'OSError'>",
          "evalue": "Not available",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mget_ipython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msystem\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpip install pyspellchecker\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/lib/python3.12/site-packages/IPython/core/interactiveshell.py:2653\u001b[0m, in \u001b[0;36mInteractiveShell.system_piped\u001b[0;34m(self, cmd)\u001b[0m\n\u001b[1;32m   2648\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBackground processes not supported.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   2650\u001b[0m \u001b[38;5;66;03m# we explicitly do NOT return the subprocess status code, because\u001b[39;00m\n\u001b[1;32m   2651\u001b[0m \u001b[38;5;66;03m# a non-None value would trigger :func:`sys.displayhook` calls.\u001b[39;00m\n\u001b[1;32m   2652\u001b[0m \u001b[38;5;66;03m# Instead, we store the exit_code in user_ns.\u001b[39;00m\n\u001b[0;32m-> 2653\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muser_ns[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_exit_code\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43msystem\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvar_expand\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcmd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdepth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/lib/python3.12/site-packages/IPython/utils/_process_emscripten.py:11\u001b[0m, in \u001b[0;36msystem\u001b[0;34m(cmd)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msystem\u001b[39m(cmd):\n\u001b[0;32m---> 11\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNot available\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "\u001b[0;31mOSError\u001b[0m: Not available"
          ],
          "output_type": "error"
        }
      ],
      "execution_count": 6
    },
    {
      "id": "7e37c786-ac41-421b-a3dc-51f8214023ac",
      "cell_type": "code",
      "source": "import os\nfrom pathlib import Path\nfrom spellchecker import SpellChecker  # from pyspellchecker\nimport nltk\nfrom nltk.tokenize import word_tokenize\nfrom nltk.tokenize.treebank import TreebankWordDetokenizer\nfrom tkinter import filedialog\nimport tkinter as tk\nimport csv\nfrom datetime import datetime\nfrom collections import Counter\n\n\n# ----------------------------\n# NLTK setup\n# ----------------------------\ndef ensure_nltk():\n    \"\"\"Ensure required NLTK resources exist (download once if missing).\"\"\"\n    try:\n        nltk.data.find('tokenizers/punkt')\n    except LookupError:\n        nltk.download('punkt', quiet=True)\n\n\n# ----------------------------\n# Folder selection helpers\n# ----------------------------\ndef select_folder_dialog(title):\n    \"\"\"Use a single hidden Tk root for each dialog.\"\"\"\n    root = tk.Tk()\n    root.withdraw()\n    try:\n        return filedialog.askdirectory(title=title) or None\n    finally:\n        root.destroy()\n\n\n# ----------------------------\n# Tokenization and filtering\n# ----------------------------\ndef tokenize_text(text):\n    \"\"\"Tokenize text into tokens.\"\"\"\n    return word_tokenize(text)\n\n\ndef is_candidate_word(tok):\n    \"\"\"\n    Decide whether a token should be spell-checked.\n    Skip short tokens, non-alphabetic items, and ALL-CAPS (likely acronyms).\n    \"\"\"\n    if not isinstance(tok, str):\n        return False\n    if not tok.isalpha():\n        return False\n    if len(tok) <= 2:\n        return False\n    if tok.isupper():\n        return False\n    return True\n\n\ndef count_real_words(text):\n    \"\"\"Count alphabetic tokens to compute a meaningful error rate.\"\"\"\n    return sum(1 for t in tokenize_text(text) if isinstance(t, str) and t.isalpha())\n\n\n# ----------------------------\n# Spelling analysis and correction\n# ----------------------------\ndef analyze_spelling(text, spell_checker: SpellChecker):\n    \"\"\"\n    Return (corrections_dict, error_count).\n    corrections_dict maps the original surface form -> suggested correction (or original if none).\n    error_count is the number of misspelled token instances (not unique types).\n    \"\"\"\n    tokens = tokenize_text(text)\n    candidate_indices = [i for i, t in enumerate(tokens) if is_candidate_word(t)]\n    candidate_words = [tokens[i].lower() for i in candidate_indices]\n    misspelled = spell_checker.unknown(candidate_words)\n\n    corrections = {}\n    error_count = 0\n    for idx, lw in zip(candidate_indices, candidate_words):\n        if lw in misspelled:\n            surface = tokens[idx]\n            suggestion = spell_checker.correction(lw) or surface\n            # Record only first suggestion per surface form for the report\n            corrections.setdefault(surface, suggestion)\n            error_count += 1\n\n    return corrections, error_count\n\n\ndef correct_spelling(text, spell_checker: SpellChecker):\n    \"\"\"\n    Correct misspelled candidate tokens while preserving punctuation/spacing.\n    Safely coalesce None suggestions to the original token.\n    \"\"\"\n    detok = TreebankWordDetokenizer()\n    tokens = tokenize_text(text)\n\n    candidate_indices = [i for i, t in enumerate(tokens) if is_candidate_word(t)]\n    candidate_words = [tokens[i].lower() for i in candidate_indices]\n    misspelled = spell_checker.unknown(candidate_words)\n\n    for i, lw in zip(candidate_indices, candidate_words):\n        if lw in misspelled:\n            orig = tokens[i]\n            suggestion = spell_checker.correction(lw)\n            if not isinstance(suggestion, str) or not suggestion:\n                # No safe suggestion—keep original token\n                continue\n            if orig.istitle():\n                suggestion = suggestion.capitalize()\n            elif orig.isupper():\n                suggestion = suggestion.upper()\n            tokens[i] = suggestion\n\n    # Final guard: every token must be a string for detokenizer\n    tokens = [t if isinstance(t, str) else \"\" for t in tokens]\n    return detok.detokenize(tokens)\n\n\n# ----------------------------\n# CSV export and report\n# ----------------------------\ndef export_to_csv(error_summary: dict, output_folder: Path):\n    \"\"\"\n    Write summary and detailed CSVs.\n    error_summary structure:\n      filename: {\n        'error_count': int,\n        'errors': {surface: suggestion},\n        'original_text': str\n      }\n    \"\"\"\n    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n\n    summary_csv_path = output_folder / f\"spelling_error_summary_{timestamp}.csv\"\n    with summary_csv_path.open('w', newline='', encoding='utf-8') as csvfile:\n        writer = csv.writer(csvfile)\n        writer.writerow(['Filename', 'Total Word Count', 'Error Count', 'Error Rate (%)'])\n        for filename, data in error_summary.items():\n            total_words = count_real_words(data['original_text'])\n            error_rate = (data['error_count'] / total_words * 100) if total_words > 0 else 0\n            writer.writerow([filename, total_words, data['error_count'], f\"{error_rate:.2f}\"])\n\n    detailed_csv_path = output_folder / f\"spelling_error_details_{timestamp}.csv\"\n    with detailed_csv_path.open('w', newline='', encoding='utf-8') as csvfile:\n        writer = csv.writer(csvfile)\n        writer.writerow(['Filename', 'Misspelled Word (surface)', 'Correction'])\n        for filename, data in error_summary.items():\n            for word in sorted(data['errors'].keys(), key=str.lower):\n                writer.writerow([filename, data['errors'].get(word, word), data['errors'][word]])\n\n    return str(summary_csv_path), str(detailed_csv_path)\n\n\ndef write_text_report(error_summary: dict, output_folder: Path):\n    \"\"\"Write a human-readable report to _spelling_error_report.txt.\"\"\"\n    report_path = output_folder / \"_spelling_error_report.txt\"\n    with report_path.open('w', encoding='utf-8') as report:\n        report.write(\"Spelling Error Summary Report\\n\")\n        report.write(\"=\" * 30 + \"\\n\\n\")\n        for filename, data in error_summary.items():\n            report.write(f\"File: {filename}\\n\")\n            report.write(f\"Total errors: {data['error_count']}\\n\")\n            report.write(\"Corrections:\\n\")\n            for word in sorted(data['errors'].keys(), key=str.lower):\n                report.write(f\"  {word} -> {data['errors'][word]}\\n\")\n            report.write(\"\\n\" + \"-\" * 30 + \"\\n\\n\")\n    return str(report_path)\n\n\n# ----------------------------\n# Main processing\n# ----------------------------\ndef process_folder(input_folder: Path, output_folder: Path):\n    spell = SpellChecker(language='en')\n    error_summary = {}\n\n    for entry in sorted(input_folder.iterdir()):\n        if entry.is_file() and entry.suffix.lower() == '.txt':\n            input_path = entry\n            output_path = output_folder / entry.name\n\n            try:\n                content = input_path.read_text(encoding='utf-8')\n            except UnicodeDecodeError:\n                content = input_path.read_text(encoding='utf-8', errors='replace')\n\n            errors, error_count = analyze_spelling(content, spell)\n            error_summary[entry.name] = {\n                'error_count': error_count,\n                'errors': errors,\n                'original_text': content\n            }\n\n            corrected = correct_spelling(content, spell)\n            output_path.write_text(corrected, encoding='utf-8')\n\n            print(f\"Processed: {entry.name}\")\n            print(f\"Number of spelling errors found: {error_count}\")\n            if errors:\n                print(\"Misspelled words and their corrections:\")\n                for w in sorted(errors.keys(), key=str.lower):\n                    print(f\"  {w} -> {errors[w]}\")\n            print(\"-\" * 50)\n\n    summary_csv, detailed_csv = export_to_csv(error_summary, output_folder)\n    report_path = write_text_report(error_summary, output_folder)\n\n    # ⭐ New feature: show top 5 most frequent misspelled words across all files\n    all_errors = []\n    for data in error_summary.values():\n        for w in data[\"errors\"].keys():\n            all_errors.append(w.lower())\n\n    if all_errors:\n        counter = Counter(all_errors)\n        top5 = counter.most_common(5)\n        print(\"\\nTop 5 Most Frequent Misspelled Words:\")\n        for w, freq in top5:\n            print(f\"  {w} (appeared {freq} times across files)\")\n        print(\"-\" * 50)\n    else:\n        print(\"\\nNo spelling errors detected in the processed files.\")\n        print(\"-\" * 50)\n\n    print(\"\\nSpelling correction completed!\")\n    print(f\"Corrected files and reports are in: {output_folder}\")\n    print(f\"Summary CSV: {Path(summary_csv).name}\")\n    print(f\"Detailed CSV: {Path(detailed_csv).name}\")\n    print(f\"Text report: {Path(report_path).name}\")\n\n\n# ----------------------------\n# Entrypoint\n# ----------------------------\ndef main():\n    ensure_nltk()\n\n    print(\"Please select input folder...\")\n    input_dir = select_folder_dialog(\"Select Input Folder\")\n    if not input_dir:\n        print(\"No input folder selected. Exiting...\")\n        return\n\n    print(\"Please select output folder...\")\n    output_dir = select_folder_dialog(\"Select Output Folder\")\n    if not output_dir:\n        print(\"No output folder selected. Exiting...\")\n        return\n\n    input_folder = Path(input_dir)\n    output_folder = Path(output_dir)\n    output_folder.mkdir(parents=True, exist_ok=True)\n\n    process_folder(input_folder, output_folder)\n\n\nif __name__ == \"__main__\":\n    main()\n\n\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "ename": "<class 'ModuleNotFoundError'>",
          "evalue": "No module named 'spellchecker'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[7], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpathlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Path\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mspellchecker\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SpellChecker  \u001b[38;5;66;03m# from pyspellchecker\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtokenize\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m word_tokenize\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'spellchecker'"
          ],
          "output_type": "error"
        }
      ],
      "execution_count": 7
    },
    {
      "id": "41e29b61-de0f-4266-b32d-5c25cbad30e2",
      "cell_type": "code",
      "source": "pip uninstall spellchecker",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "Found existing installation: spellchecker 0.4\n,Uninstalling spellchecker-0.4:\n,  Would remove:\n,    /opt/anaconda3/lib/python3.11/site-packages/spellchecker-0.4.dist-info/*\n,    /opt/anaconda3/lib/python3.11/site-packages/spellchecker/*\n,Proceed (Y/n)? "
        }
      ],
      "execution_count": null
    },
    {
      "id": "fcd9bd44-62b3-453d-93bc-d147c4398d1e",
      "cell_type": "code",
      "source": "Y",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    }
  ]
}